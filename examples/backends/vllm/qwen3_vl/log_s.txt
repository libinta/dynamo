[W204 19:19:46.124244627 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:37
       new kernel: registered at /root/workspace/frameworks.ai.pytorch.ipex-gpu/build/Release/csrc/gpu/csrc/gpu/xpu/ATen/RegisterXPU_0.cpp:172 (function operator())
2026-02-04 19:19:51,107 - dynamo.nixl_connect - WARNING - dynamo.nixl_connect: Failed to load CuPy for GPU acceleration, utilizing numpy to provide CPU based operations.
2026-02-04 19:19:51,177 - dynamo.vllm.multimodal_handlers.encode_worker_handler - WARNING - Failed to import cupy, falling back to numpy: No module named 'cupy'.
[2m2026-02-04T19:19:51.201707Z[0m [32m INFO[0m [2margs.create_kv_transfer_config[0m[2m:[0m Using vLLM defaults for kv_transfer_config
[2m2026-02-04T19:19:51.201765Z[0m [32m INFO[0m [2margs.create_kv_events_config[0m[2m:[0m Using env-var DYN_VLLM_KV_EVENT_PORT=20080 to create kv_events_config
[2m2026-02-04T19:19:51.201812Z[0m [32m INFO[0m [2margs.overwrite_args[0m[2m:[0m Using kv_events_config for publishing vLLM kv events over zmq: KVEventsConfig(enable_kv_cache_events=True, publisher='zmq', endpoint='tcp://*:20080', replay_endpoint=None, buffer_steps=10000, hwm=100000, max_queue_size=100000, topic='') (use_kv_events=True)
[2m2026-02-04T19:19:51.208359Z[0m [32m INFO[0m [2mdynamo_runtime::distributed[0m[2m:[0m Initializing KV store discovery backend
[2m2026-02-04T19:19:51.208462Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::manager[0m[2m:[0m Initializing NetworkManager with NATS request plane [3mmode[0m[2m=[0mnats
[2m2026-02-04T19:19:51.354443Z[0m [32m INFO[0m [2mdynamo_runtime::distributed[0m[2m:[0m Added NATS service dynamo_backend
WARNING 02-04 19:19:51 [_logger.py:68] Found PROMETHEUS_MULTIPROC_DIR was set by user. This directory must be wiped between vLLM runs or you will find inaccurate metrics. Unset the variable and vLLM will properly handle cleanup.
INFO 02-04 19:19:51 [model.py:530] Resolved architecture: Qwen3VLForConditionalGeneration
WARNING 02-04 19:19:51 [_logger.py:68] Casting torch.bfloat16 to torch.float16.
INFO 02-04 19:19:51 [model.py:1545] Using max model len 4096
WARNING 02-04 19:19:51 [logger.py:147] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 02-04 19:19:51 [model.py:530] Resolved architecture: Qwen3VLForConditionalGeneration
WARNING 02-04 19:19:51 [_logger.py:68] Casting torch.bfloat16 to torch.float16.
INFO 02-04 19:19:51 [model.py:1545] Using max model len 4096
INFO 02-04 19:19:51 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 02-04 19:19:51 [vllm.py:630] Asynchronous scheduling is enabled.
INFO 02-04 19:19:51 [vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.
WARNING 02-04 19:19:51 [_logger.py:68] Enforce eager set, overriding optimization level to -O0
[2026-02-04 19:19:54.416] [warning] [sycl_collector.h:388] Another subscriber already subscribed to Sycl runtime events, so PTI will not subscribe to them. It will affect correctness of PTI profile: e.g. report zero XPU time for CPU callers of GPU kernels.
[W204 19:19:55.180314497 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:37
       new kernel: registered at /root/workspace/frameworks.ai.pytorch.ipex-gpu/build/Release/csrc/gpu/csrc/gpu/xpu/ATen/RegisterXPU_0.cpp:172 (function operator())
[2m2026-02-04T19:19:59.049671Z[0m [32m INFO[0m [2mcore.__init__[0m[2m:[0m Initializing a V1 LLM engine (v0.14.1.dev0+gb17039bcc.d20260128) with config: model='/software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/', speculative_config=None, tokenizer='/software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=fp8, enforce_eager=True, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=xpu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=/software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': [], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [2048], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': None, 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': False, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': None, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=1766)[0;0m /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
[0;36m(EngineCore_DP0 pid=1766)[0;0m   _C._set_float32_matmul_precision(precision)
[2m2026-02-04T19:19:59.624543Z[0m [32m INFO[0m [2mparallel_state.init_distributed_environment[0m[2m:[0m world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.26.46.160:43897 backend=xccl
[2m2026-02-04T19:19:59.633694Z[0m [32m INFO[0m [2mparallel_state.initialize_model_parallel[0m[2m:[0m rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
2026:02:04-19:19:59:( 1766) |CCL_WARN| value of CCL_ATL_TRANSPORT changed to be ofi (default:mpi)
2026:02:04-19:19:59:( 1766) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL
[2m2026-02-04T19:20:02.205093Z[0m [32m INFO[0m [2mgpu_model_runner.load_model[0m[2m:[0m Starting to load model /software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/...
[2m2026-02-04T19:20:02.821454Z[0m [32m INFO[0m [2mxpu.get_vit_attn_backend[0m[2m:[0m Using backend AttentionBackendEnum.FLASH_ATTN for vit attention
[2m2026-02-04T19:20:02.822250Z[0m [32m INFO[0m [2mmm_encoder_attention.__init__[0m[2m:[0m Using AttentionBackendEnum.FLASH_ATTN for MMEncoderAttention.
[2m2026-02-04T19:20:02.909031Z[0m [32m INFO[0m [2mxpu.get_attn_backend_cls[0m[2m:[0m Setting VLLM_KV_CACHE_LAYOUT to 'NHD' for XPU; only NHD layout is supported by XPU attention kernels.
[2m2026-02-04T19:20:02.909069Z[0m [32m INFO[0m [2mxpu.get_attn_backend_cls[0m[2m:[0m Using Flash Attention backend.
[0;36m(EngineCore_DP0 pid=1766)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=1766)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:34<00:34, 34.73s/it]
[0;36m(EngineCore_DP0 pid=1766)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:18<00:00, 39.85s/it]
[0;36m(EngineCore_DP0 pid=1766)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:18<00:00, 39.08s/it]
[0;36m(EngineCore_DP0 pid=1766)[0;0m 
[2m2026-02-04T19:21:21.397627Z[0m [32m INFO[0m [2mdefault_loader.load_weights[0m[2m:[0m Loading weights took 78.23 seconds
[2m2026-02-04T19:21:22.005862Z[0m [32m INFO[0m [2mgpu_model_runner.load_model[0m[2m:[0m Model loading took 4.82 GiB memory and 79.093513 seconds
[2m2026-02-04T19:21:22.317779Z[0m [32m INFO[0m [2mxpu_worker.determine_available_memory[0m[2m:[0m Before memory profiling run, total GPU memory: 23256.00 MB, model load takes 4950.02 MB, free gpu memory is 23256.00 MB.
[2m2026-02-04T19:21:22.317835Z[0m [32m INFO[0m [2mgpu_model_runner.profile_run[0m[2m:[0m Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[2m2026-02-04T19:21:42.788657Z[0m [32m INFO[0m [2mxpu_worker.determine_available_memory[0m[2m:[0m After memory profiling run, peak memory usage is 7054.02 MB,torch mem is 4950.02 MB, non-torch mem is 128.00 MB, free gpu memory is 18177.98 MB.
[2m2026-02-04T19:21:42.789038Z[0m [32m INFO[0m [2mkv_cache_utils._report_kv_cache_config[0m[2m:[0m GPU KV cache size: 65,600 tokens
[2m2026-02-04T19:21:42.789086Z[0m [32m INFO[0m [2mkv_cache_utils._report_kv_cache_config[0m[2m:[0m Maximum concurrency for 4,096 tokens per request: 16.02x
[2m2026-02-04T19:21:42.944197Z[0m [32m INFO[0m [2mutils.get_kv_cache_layout[0m[2m:[0m `_KV_CACHE_LAYOUT_OVERRIDE` variable detected. Setting KV cache layout to NHD.
[2m2026-02-04T19:21:43.170137Z[0m [32m INFO[0m [2mcore._initialize_kv_caches[0m[2m:[0m init engine (profile, create kv cache, warmup model) took 21.16 seconds
[2m2026-02-04T19:21:43.175042Z[0m [32m INFO[0m [2mkv_events.__init__[0m[2m:[0m Starting ZMQ publisher thread
[2m2026-02-04T19:21:43.423671Z[0m [32m INFO[0m [2mvllm.__post_init__[0m[2m:[0m Asynchronous scheduling is enabled.
[2m2026-02-04T19:21:43.423734Z[0m [33m WARN[0m [2m_logger.warning[0m[2m:[0m Inductor compilation was disabled by user settings, optimizations settings that are only active during inductor compilation will be ignored.
[2m2026-02-04T19:21:43.618194Z[0m [32m INFO[0m [2mmain.setup_vllm_engine[0m[2m:[0m VllmWorker for /software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/ has been initialized
[2m2026-02-04T19:21:43.618262Z[0m [32m INFO[0m [2mengine_monitor.__init__[0m[2m:[0m VllmEngineMonitor initialized and health check task started.
[2m2026-02-04T19:21:43.618315Z[0m [32m INFO[0m [2mmain.setup_kv_event_publisher[0m[2m:[0m KV event publisher for dp_rank=0 subscribing to vLLM at tcp://127.0.0.1:20080
[2m2026-02-04T19:21:43.618336Z[0m [32m INFO[0m [2mdynamo_llm::kv_router::publisher[0m[2m:[0m Initializing KvEventPublisher for worker 7587892651801827337 in component backend
[2m2026-02-04T19:21:43.618403Z[0m [32m INFO[0m [2mmain.setup_kv_event_publisher[0m[2m:[0m Worker reading KV events for dp_rank=0 from tcp://127.0.0.1:20080
[2m2026-02-04T19:21:43.618765Z[0m [32m INFO[0m [2mmain.init[0m[2m:[0m Registered engine routes: /engine/sleep, /engine/wake_up
[2m2026-02-04T19:21:43.618794Z[0m [32m INFO[0m [2mmain.init[0m[2m:[0m Registering model with endpoint types: chat,completions
[2m2026-02-04T19:21:43.619132Z[0m [32m INFO[0m [2mmain.register_vllm_model[0m[2m:[0m Getting engine runtime configuration metadata from vLLM engine for chat,completions...
[2m2026-02-04T19:21:43.619157Z[0m [32m INFO[0m [2mmain.get_engine_cache_info[0m[2m:[0m Cache config values: {'num_gpu_blocks': 1025}
[2m2026-02-04T19:21:43.619171Z[0m [32m INFO[0m [2mmain.get_engine_cache_info[0m[2m:[0m Scheduler config values: {'max_num_seqs': 256, 'max_num_batched_tokens': 2048}
[2m2026-02-04T19:21:43.621796Z[0m [32m INFO[0m [2mdynamo_runtime::discovery::kv_store[0m[2m:[0m KVStoreDiscovery::register: EventChannel bucket=v1/event_channels, key=dynamo//kv_metrics/694d9c2a1871d809
[2m2026-02-04T19:21:43.622866Z[0m [32m INFO[0m [2mdynamo_runtime::transports::event_plane[0m[2m:[0m EventPublisher registered with discovery [3mtopic[0m[2m=[0mkv_metrics [3mtransport[0m[2m=[0mNats [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.632134Z[0m [32m INFO[0m [2m_core[0m[2m:[0m Registered base model '/software/data/pytorch/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17/' MDC
[2m2026-02-04T19:21:43.633703Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::manager[0m[2m:[0m Creating NATS request plane server
[2m2026-02-04T19:21:43.633741Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m NatsMultiplexedServer::register_endpoint called [3mendpoint_name[0m[2m=[0mlist_loras [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633752Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Successfully retrieved service group
[2m2026-02-04T19:21:43.633765Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Registering NATS endpoint [3mendpoint_name[0m[2m=[0mlist_loras [3mendpoint_with_id[0m[2m=[0mlist_loras-694d9c2a1871d809 [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633769Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Starting NATS push endpoint listener (blocking) [3mendpoint_name[0m[2m=[0mlist_loras [3mendpoint_with_id[0m[2m=[0mlist_loras-694d9c2a1871d809
[2m2026-02-04T19:21:43.633772Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m NatsMultiplexedServer::register_endpoint called [3mendpoint_name[0m[2m=[0mgenerate [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633780Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m NatsMultiplexedServer::register_endpoint called [3mendpoint_name[0m[2m=[0mload_lora [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633787Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Successfully retrieved service group
[2m2026-02-04T19:21:43.633795Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Successfully retrieved service group
[2m2026-02-04T19:21:43.633768Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m NatsMultiplexedServer::register_endpoint called [3mendpoint_name[0m[2m=[0mclear_kv_blocks [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633805Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Successfully retrieved service group
[2m2026-02-04T19:21:43.633806Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Registering NATS endpoint [3mendpoint_name[0m[2m=[0mgenerate [3mendpoint_with_id[0m[2m=[0mgenerate-694d9c2a1871d809 [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633799Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m NatsMultiplexedServer::register_endpoint called [3mendpoint_name[0m[2m=[0munload_lora [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633811Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Starting NATS push endpoint listener (blocking) [3mendpoint_name[0m[2m=[0mgenerate [3mendpoint_with_id[0m[2m=[0mgenerate-694d9c2a1871d809
[2m2026-02-04T19:21:43.633809Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Registering NATS endpoint [3mendpoint_name[0m[2m=[0mload_lora [3mendpoint_with_id[0m[2m=[0mload_lora-694d9c2a1871d809 [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633817Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Successfully retrieved service group
[2m2026-02-04T19:21:43.633817Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Starting NATS push endpoint listener (blocking) [3mendpoint_name[0m[2m=[0mload_lora [3mendpoint_with_id[0m[2m=[0mload_lora-694d9c2a1871d809
[2m2026-02-04T19:21:43.633821Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Registering NATS endpoint [3mendpoint_name[0m[2m=[0mclear_kv_blocks [3mendpoint_with_id[0m[2m=[0mclear_kv_blocks-694d9c2a1871d809 [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633827Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Starting NATS push endpoint listener (blocking) [3mendpoint_name[0m[2m=[0mclear_kv_blocks [3mendpoint_with_id[0m[2m=[0mclear_kv_blocks-694d9c2a1871d809
[2m2026-02-04T19:21:43.633828Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Registering NATS endpoint [3mendpoint_name[0m[2m=[0munload_lora [3mendpoint_with_id[0m[2m=[0munload_lora-694d9c2a1871d809 [3mnamespace[0m[2m=[0mdynamo [3mcomponent[0m[2m=[0mbackend [3minstance_id[0m[2m=[0m7587892651801827337
[2m2026-02-04T19:21:43.633832Z[0m [32m INFO[0m [2mdynamo_runtime::pipeline::network::ingress::nats_server[0m[2m:[0m Starting NATS push endpoint listener (blocking) [3mendpoint_name[0m[2m=[0munload_lora [3mendpoint_with_id[0m[2m=[0munload_lora-694d9c2a1871d809
[2m2026-02-04T19:24:06.184496Z[0m [32m INFO[0m [2mhttp_client.get_http_client[0m[2m:[0m Shared HTTP client initialized with timeout=30.0s
